#!/usr/bin/env python3
"""
Script d'indexation des offres d'emploi dans Elasticsearch.

Usage:
    python scripts/index_to_elasticsearch.py --source francetravail
    python scripts/index_to_elasticsearch.py --source francetravail --file offers_kw_data_engineer.jsonl
    python scripts/index_to_elasticsearch.py --source francetravail --force
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv

# Ajouter le rÃ©pertoire parent au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from pipelines.storage.elasticsearch import ElasticsearchClient


def load_jsonl_file(file_path: Path) -> List[Dict[str, Any]]:
    """
    Charge un fichier JSONL et retourne une liste d'offres.
    
    Args:
        file_path: Chemin vers le fichier JSONL
        
    Returns:
        Liste d'offres d'emploi
    """
    offers = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                offer = json.loads(line)
                offers.append(offer)
            except json.JSONDecodeError as e:
                print(f"âš  Erreur ligne {line_num} dans {file_path.name}: {e}")
    return offers


def get_normalized_files(source: str, data_dir: Path, specific_file: str = None) -> List[Path]:
    """
    RÃ©cupÃ¨re la liste des fichiers normalisÃ©s Ã  indexer.
    
    Args:
        source: Nom de la source (francetravail, apec, etc.)
        data_dir: RÃ©pertoire racine des donnÃ©es
        specific_file: Nom d'un fichier spÃ©cifique (optionnel)
        
    Returns:
        Liste des chemins de fichiers JSONL
    """
    normalized_dir = data_dir / "normalized" / source
    
    if not normalized_dir.exists():
        print(f"âŒ Le rÃ©pertoire {normalized_dir} n'existe pas")
        return []
    
    if specific_file:
        file_path = normalized_dir / specific_file
        if file_path.exists():
            return [file_path]
        else:
            print(f"âŒ Le fichier {file_path} n'existe pas")
            return []
    
    # RÃ©cupÃ©rer tous les fichiers JSONL (exclure le dossier old)
    files = [f for f in normalized_dir.glob("*.jsonl") if f.is_file()]
    return sorted(files)


def index_files(
    es_client: ElasticsearchClient,
    files: List[Path],
    batch_size: int = 500,
    verbose: bool = False
) -> Dict[str, int]:
    """
    Indexe tous les fichiers dans Elasticsearch.
    
    Args:
        es_client: Client Elasticsearch
        files: Liste des fichiers Ã  indexer
        batch_size: Taille des batches d'indexation
        verbose: Si True, affiche les dÃ©tails des erreurs
        
    Returns:
        Statistiques d'indexation
    """
    total_stats = {
        "total_offers": 0,
        "indexed": 0,
        "duplicates": 0,
        "errors": 0,
        "files_processed": 0,
        "error_details": {}
    }
    
    for file_path in files:
        print(f"\nğŸ“„ Traitement de {file_path.name}...")
        
        offers = load_jsonl_file(file_path)
        if not offers:
            print(f"âš  Aucune offre trouvÃ©e dans {file_path.name}")
            continue
        
        print(f"   â†’ {len(offers)} offres chargÃ©es")
        
        # Indexer en batch
        stats = es_client.bulk_index_offers(offers, batch_size=batch_size, verbose=verbose)
        
        if stats['duplicates'] > 0:
            print(f"   âœ“ {stats['indexed']} indexÃ©es, {stats['duplicates']} doublons, {stats['errors']} erreurs")
        else:
            print(f"   âœ“ {stats['indexed']} indexÃ©es, {stats['errors']} erreurs")
        
        total_stats["total_offers"] += len(offers)
        total_stats["indexed"] += stats["indexed"]
        total_stats["duplicates"] += stats.get("duplicates", 0)
        total_stats["errors"] += stats["errors"]
        total_stats["files_processed"] += 1
        
        # Accumuler les types d'erreurs
        for error_type, count in stats.get("error_details", {}).items():
            total_stats["error_details"][error_type] = total_stats["error_details"].get(error_type, 0) + count
    
    return total_stats


def main():
    """Point d'entrÃ©e principal du script."""
    parser = argparse.ArgumentParser(
        description="Indexe les offres d'emploi normalisÃ©es dans Elasticsearch"
    )
    parser.add_argument(
        "--source",
        type=str,
        default="francetravail",
        help="Source des donnÃ©es (francetravail, apec, etc.)"
    )
    parser.add_argument(
        "--file",
        type=str,
        help="Nom d'un fichier spÃ©cifique Ã  indexer (optionnel)"
    )
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=Path("./data"),
        help="RÃ©pertoire racine des donnÃ©es"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="RecrÃ©e l'index (supprime les donnÃ©es existantes)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=500,
        help="Taille des batches d'indexation"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Affiche les dÃ©tails des erreurs"
    )
    
    args = parser.parse_args()
    
    # Charger les variables d'environnement
    env_path = Path(__file__).parent.parent / "config" / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ“ Variables d'environnement chargÃ©es depuis {env_path}")
    else:
        print(f"âš  Fichier .env non trouvÃ© ({env_path}). Utilisation des valeurs par dÃ©faut.")
    
    # Initialiser le client Elasticsearch
    try:
        print(f"\nğŸ”Œ Connexion Ã  Elasticsearch...")
        es_client = ElasticsearchClient()
    except Exception as e:
        print(f"\nâŒ Impossible de se connecter Ã  Elasticsearch: {e}")
        print("\nAssurez-vous que Elasticsearch est dÃ©marrÃ©:")
        print("   docker-compose up -d")
        sys.exit(1)
    
    # CrÃ©er l'index
    print(f"\nğŸ“‘ Configuration de l'index...")
    try:
        es_client.create_index(force=args.force)
    except Exception as e:
        print(f"âŒ Erreur lors de la configuration de l'index: {e}")
        sys.exit(1)
    
    # RÃ©cupÃ©rer les fichiers Ã  indexer
    print(f"\nğŸ“‚ Recherche des fichiers Ã  indexer...")
    files = get_normalized_files(args.source, args.data_dir, args.file)
    
    if not files:
        print("âŒ Aucun fichier Ã  indexer")
        sys.exit(1)
    
    print(f"âœ“ {len(files)} fichier(s) trouvÃ©(s)")
    
    # Indexer les fichiers
    print(f"\nğŸš€ Indexation en cours...")
    stats = index_files(es_client, files, batch_size=args.batch_size, verbose=args.verbose)
    
    # Forcer le refresh de l'index pour que les stats soient Ã  jour
    es_client.client.indices.refresh(index=es_client.index_name)
    
    # Afficher le rÃ©sumÃ©
    print(f"\n{'='*60}")
    print(f"ğŸ“Š RÃ‰SUMÃ‰ DE L'INDEXATION")
    print(f"{'='*60}")
    print(f"Fichiers traitÃ©s    : {stats['files_processed']}")
    print(f"Offres totales      : {stats['total_offers']}")
    print(f"Offres indexÃ©es     : {stats['indexed']}")
    print(f"Doublons ignorÃ©s    : {stats['duplicates']}")
    print(f"Erreurs             : {stats['errors']}")
    if stats['total_offers'] > 0:
        success_rate = (stats['indexed'] / stats['total_offers']) * 100
        print(f"Taux de succÃ¨s      : {success_rate:.1f}%")
    
    # Afficher le dÃ©tail des types d'erreurs s'il y en a
    if stats.get('error_details'):
        print(f"\nğŸ“‹ Types d'erreurs:")
        for error_type, count in sorted(stats['error_details'].items(), key=lambda x: x[1], reverse=True):
            print(f"   - {error_type}: {count}")
    
    print(f"{'='*60}")
    
    # Afficher les statistiques de l'index
    try:
        index_stats = es_client.get_stats()
        print(f"\nğŸ“ˆ Statistiques de l'index '{index_stats['index_name']}':")
        print(f"Documents totaux    : {index_stats['total_documents']}")
        print(f"Taille              : {index_stats['size_in_bytes'] / 1024 / 1024:.2f} MB")
    except Exception as e:
        print(f"âš  Impossible de rÃ©cupÃ©rer les statistiques: {e}")
    
    print(f"\nâœ… Indexation terminÃ©e!")
    print(f"\nğŸ’¡ AccÃ¨s:")
    print(f"   - Elasticsearch: {es_client.host}")
    print(f"   - Kibana: http://localhost:5601")
    print(f"   - Index: {es_client.index_name}")


if __name__ == "__main__":
    main()
