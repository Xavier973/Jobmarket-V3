# JobMarket â€” Data Job Market Analytics (V3)

## AperÃ§u
JobMarket V3 repart sur une architecture modulaire pour analyser le marche de l'emploi data en France. La collecte d'offres se fait via l'API France Travail, puis les donnees sont normalisees dans un schema commun pour faciliter l'ajout d'autres sources (APEC, Welcome to the Jungle, Indeed, LinkedIn).

## Objectifs
- Remplacer le scraping par l'API France Travail.
- Decoupler l'ingestion, le stockage et la visualisation.
- Garder un schema canonique pour accueillir plusieurs sources.
- Choisir une nouvelle solution de dashboard (etude en cours).

## FonctionnalitÃ©s clÃ©s
- âœ… Collecte automatisÃ©e via API France Travail
- âœ… Normalisation multi-sources (schÃ©ma canonique)
- âœ… **DÃ©tection automatique du tÃ©lÃ©travail** (26.8% des offres)
- âœ… Indexation Elasticsearch avec gÃ©olocalisation
- âœ… API REST FastAPI pour requÃªtes et analyses
- âœ… Dashboard React/Next.js (en dÃ©veloppement)

## Architecture cible
- **Ingestion** : pipeline multi-sources (adapters par source) -> donnees brutes -> normalisees.
- **Stockage** : moteur d'analyse (Elasticsearch par defaut) et indexation optimisee.
- **API** : service de lecture FastAPI pour exposer les donnees au dashboard.
- **Dashboard** : interface React + Next.js connectee a l'API.

## Stack technique (base)
- Python 3.9+
- Elasticsearch 8.x (par defaut)
- FastAPI (API backend)
- Next.js 14 + React 18 + TypeScript (Dashboard frontend)
- Docker + Docker Compose

## Structure du projet (V3)
```
Jobmarket_V3/
â”œâ”€â”€ pipelines/           # Pipeline d'ingestion et normalisation
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ sources/     # Adapters par source (francetravail, apec, etc.)
â”‚   â”‚   â”œâ”€â”€ models.py    # SchÃ©ma canonique JobOffer
â”‚   â”‚   â”œâ”€â”€ normalizer.py
â”‚   â”‚   â””â”€â”€ io.py
â”‚   â””â”€â”€ storage/         # Module de stockage Elasticsearch
â”‚       â”œâ”€â”€ elasticsearch.py
â”‚   backend/             # API FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      # Point d'entrÃ©e API
â”‚   â”‚   â”œâ”€â”€ config.py    # Configuration
â”‚   â”‚   â”œâ”€â”€ models/      # ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ services/    # Logique mÃ©tier (ES, analytics)
â”‚   â”‚   â””â”€â”€ api/v1/      # Routes API
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/            # Dashboard React + Next.js
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/         # Pages Next.js
â”‚   â”‚   â”œâ”€â”€ components/  # Composants React
â”‚   â”‚   â”œâ”€â”€ lib/         # Client API, utilitaires
â”‚   â”‚   â”œâ”€â”€ hooks/       # Custom hooks
â”‚   â”‚   â””â”€â”€ types/       # Types TypeScript
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ scripts/             # Scripts utilitaires
â”‚   â”œâ”€â”€ index_to_elasticsearch.py  # Indexation dans Elasticsearch
â”‚   â”œâ”€â”€ analysis/        # Scripts d'analyse des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ analyze_data_analyst.py
â”‚   â”‚   â””â”€â”€ examples_visualization.py
â”‚   â””â”€â”€ maintenance/     # Scripts de maintenance
â”‚       â””â”€â”€ fix_line_endings.py
â”‚
â”œâ”€â”€ tests/               # Tests de validation
â”‚   â””â”€â”€ test_enriched_mapping.py
â”‚
â”œâ”€â”€ data/                # DonnÃ©es brutes et normalisÃ©es
â”‚   â”œâ”€â”€ raw/francetravail/
â”‚   â””â”€â”€ normalized/francetravail/
â”‚
â”œâ”€â”€ docs/                # Documentation
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ data-model.md
â”‚   â”œâ”€â”€ elasticsearch.md
â”‚   â”œâ”€â”€ dashboard-architecture.md
â”‚   â”œâ”€â”€ guide-collecte-francetravail.md
â”‚   â””â”€â”€ ops.md
â”‚
â”œâ”€â”€ config/              # Configuration
â”‚   â””â”€â”€ .env.example
â”‚
â”œâ”€â”€ docker-compose.yml   # Elasticsearch + Kibana + Backend + Frontend
â”‚
â”œâ”€â”€ docker-compose.yml   # Elasticsearch + Kibana
â””â”€â”€ requirements.txt     # DÃ©pendances Python
```

## Configuration
Exemple d'environnement : [config/.env.example](config/.env.example)

Variables principales :
- FT_API_BASE_URL=https://api.francetravail.io/partenaire/offresdemploi
- FT_API_TOKEN_URL=https://entreprise.francetravail.fr/connexion/oauth2/access_token?realm=%2Fpartenaire
- FT_API_CLIENT_ID=
- FT_API_CLIENT_SECRET=
- FT_API_SEARCH_URL=https://api.francetravail.io/partenaire/offresdemploi/v2/offres/search
- FT_API_SCOPE=api_offresdemploiv2 o2dsoffre
- INGEST_OUTPUT_DIR=./data

## DÃ©marrage rapide (ingestion France Travail)
1. Copier l'environnement :
   ```bash
   copy config/.env.example config/.env
   ```
2. Renseigner les variables France Travail.
3. Lancer l'ingestion :
   ```bash
   # Collecte complÃ¨te avec dÃ©coupage automatique (contourne la limite de 150)
   python -m pipelines.ingest.sources.francetravail.main --keywords "data analyst" --split-by-contract
   python -m pipelines.ingest.sources.francetravail.main --keywords "data engineer" --split-by-contract
   
   # Collecte simple (limitÃ©e Ã  150 offres par l'API)
   python -m pipelines.ingest.sources.francetravail.main --keywords "data analyst"
   
   # Collecte limitÃ©e (nombre d'offres spÃ©cifique)
   python -m pipelines.ingest.sources.francetravail.main --keywords "data analyst" --limit 200
   
   # Collecte par codes ROME
   python -m pipelines.ingest.sources.francetravail.main --rome-codes M1419,M1811,M1405
   
   # Mode Ã©chantillon (test rapide)
   python -m pipelines.ingest.sources.francetravail.main --sample
   ```

## DÃ©marrage Elasticsearch et indexation
1. DÃ©marrer Elasticsearch et Kibana :
   ```bash
   # DÃ©marrer les conteneurs Docker
   docker-compose up -d
   
   # VÃ©rifier que les services sont dÃ©marrÃ©s
   - **Backend API** : http://localhost:8000 (docs: http://localhost:8000/docs)
   - **Dashboard** : http://localhost:3000
   docker-compose ps
   ```

2. Installer les dÃ©pendances Python :
   ```bash
   pip install -r requirements.txt
   ```

3. Indexer les donnÃ©es dans Elasticsearch :
   ```bash
   # Indexer toutes les offres France Travail
   python scripts/index_to_elasticsearch.py --source francetravail
   
   # Indexer un fichier spÃ©cifique
   

## Dashboard (React + FastAPI)

### DÃ©marrage complet avec Docker

```bash
# Tout dÃ©marrer (Elasticsearch + Backend + Frontend)
docker-compose up -d

# AccÃ¨s :
# - API : http://localhost:8000/docs
# - Dashboard : http://localhost:3000
```

### DÃ©veloppement manuel

**Terminal 1 : Elasticsearch**
```bash
docker-compose up elasticsearch kibana
```

**Terminal 2 : Backend API**
```bash
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
```

**Terminal 3 : Frontend**
```bash
cd frontend
npâœ… Choix dashboard : React + FastAPI (voir [docs/dashboard-eval.md](docs/dashboard-eval.md)).
- âœ… Mise en place du service API FastAPI.
- âœ… Indexation ElasticSearch et tests d'aggregations.
- âœ… Structure frontend Next.js + pages de base.
- ðŸš§ DÃ©veloppement features dashboard (filtres, graphiques, carte).
- ðŸ“…
### Pages disponibles

- `/` - Landing page
- `/dashboard` - Vue d'ensemble (KPIs, statistiques)
- `/dashboard/offers` - Liste des offres (en dÃ©veloppement)
- `/dashboard/analytics` - Analyses avancÃ©es (en dÃ©veloppement)
- `/dashboard/map` - Carte interactive (en dÃ©veloppement)

ðŸ“– Documentation dÃ©taillÃ©e : [docs/dashboard-architecture.md](docs/dashboard-architecture.md)python scripts/index_to_elasticsearch.py --source francetravail --file offers_kw_data_engineer.jsonl
   
   # Forcer la recrÃ©ation de l'index (supprime les donnÃ©es existantes)
   python scripts/index_to_elasticsearch.py --source francetravail --force
   ```

4. AccÃ©der aux interfaces :
   - **Elasticsearch** : http://localhost:9200
   - **Kibana** : http://localhost:5601

ðŸ“– Pour plus de dÃ©tails, voir [docs/elasticsearch.md](docs/elasticsearch.md)

## Analyse des donnÃ©es collectÃ©es
```bash
# Analyser les offres Data Analyst
python scripts/analysis/analyze_data_analyst.py

# Analyser un champs spÃ©cifique - menu interactif
python scripts/analysis/analyze_field.py

# Exemples de visualisations (salaires, compÃ©tences, etc.)
python scripts/analysis/examples_visualization.py

# Tester la dÃ©tection du tÃ©lÃ©travail
python scripts/analysis/test_remote_detection.py

# Valider le mapping enrichi
python tests/test_enriched_mapping.py
```

## Filtrer les offres avec tÃ©lÃ©travail

Le systÃ¨me dÃ©tecte automatiquement les mentions du tÃ©lÃ©travail dans les descriptions d'offres.

**Statistiques :** 26.8% des offres (561 sur 2096) mentionnent le tÃ©lÃ©travail.

```bash
# Exemples de requÃªtes Elasticsearch pour filtrer par tÃ©lÃ©travail
python scripts/query_remote_offers.py

# Tester la dÃ©tection sur les donnÃ©es collectÃ©es
python scripts/analysis/test_remote_detection.py
```

**Documentation complÃ¨te :** [docs/teletravail-detection.md](docs/teletravail-detection.md)

## Maintenance
```bash
# Corriger les fins de ligne des fichiers JSONL
python scripts/maintenance/fix_line_endings.py
```

## Roadmap courte
- Etude comparative du dashboard (voir [docs/dashboard-eval.md](docs/dashboard-eval.md)).
- Mise en place du service API.
- âœ… Indexation ElasticSearch et tests d'aggregations.
- Ajout d'une 2eme source (APEC ou WTTJ) pour valider l'extensibilite.

##  Troubleshooting API France Travail
- Erreur 401: verifier `FT_API_CLIENT_ID`, `FT_API_CLIENT_SECRET` et `FT_API_SCOPE`.
- Erreur 400: verifier `FT_API_TOKEN_URL` et le format `application/x-www-form-urlencoded`.
- Erreur 429: respecter `Retry-After` et limiter le nombre d'appels par seconde.
- Aucun resultat: verifier les parametres de recherche et tester en mode bac a sable.
- **Pagination avec le paramÃ¨tre `range`**: L'API utilise le paramÃ¨tre `range` (format `"0-149"`, `"150-299"`) au lieu de `page`/`size`. Maximum 1150 offres par recherche (range 0-149 + 150-299 + ... + 1000-1149). Pour aller au-delÃ , utiliser `--split-by-contract` ou subdiviser par dates (`minCreationDate`/`maxCreationDate`).
- **Ã‰cart avec le site web**: Le site France Travail affiche beaucoup plus d'offres (ex: 1337 pour "data engineer" vs 353 via l'API). **Raison principale** : le site utilise une recherche floue qui renvoie des rÃ©sultats peu pertinents (ex: "DÃ©veloppeur COBOL" apparaÃ®t pour "data engineer"). L'API est plus stricte et ne renvoie que les offres vraiment pertinentes. **Conclusion** : Les 353 offres API sont de meilleure qualitÃ© que les 1337 du site (moins de bruit). Le site inclut aussi quelques offres partenaires (Indeed, Monster, LinkedIn) non accessibles via l'API publique.

## Licence
Projet interne / usage prive.